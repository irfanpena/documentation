---
title: Overview
description: Learn what a persona is in Tavus.
---

A **persona** defines how a Tavus replica behaves, speaks, and responds. It bundles identity, knowledge, and CVI pipeline settings to create a real-time conversational agent.


## Persona Customization Options

Each persona includes configurable fields. Here's what you can customize:

### Persona Name

Display name shown when the replica joins a call.

<Tip>
**Best Practices**

Use a clear, human-readable name
</Tip>

### System Prompt
Instructions sent to the language model to shape the replica’s tone, personality, and behavior.

<Tip>
**Best Practices**
- Define a role (e.g., “You are a cheerful tour guide.”).
- Set boundaries (e.g., “Be concise and supportive.”).
- Avoid overloading with content or factual data.
</Tip>
### Context / Knowledge Base
Background knowledge or reference information provided to the persona's language model .

<Tip>
**Best Practices**
- Add product FAQs, background details, or structured information.
- Avoid duplicating the system prompt.
- Don’t include personal user data.
</Tip>
### Pipeline Mode
Controls which CVI pipeline layers are active and how input/output flows through the system.

Options:

- `full` (default): All layers are enabled for end-to-end multimodal processing.

- `echo`: Sends raw audio or text directly to the TTS layer.

<Note> We recommend using the `full` pipeline.</Note>
### Default Replica
Sets the visual avatar or character associated with the persona.

<Note>
You can also change a persona's default replica when creating a conversation.
</Note>

### Layers

Each layer in the pipeline processes a different part of the conversation. Layers can be configured individually to tailor input/output behavior to your application needs.
- **Transport Layer**: Manages audio and video input/output using end-to-end WebRTC, currently powered by [Daily](https://www.daily.co/). It handles microphone and camera input as well as the replica's audio and video output, and is essential for all conversations.

- [**Perception Layer**](/sections/conversational-video-interface/persona/perception): Processes visual input from the user's camera or screenshare using **Raven**, Tavus's advanced multimodal perception model. This enables the persona to interpret facial expressions, on-screen content, and the surrounding environment for context-aware interactions.

- [**STT Layer**](/sections/conversational-video-interface/persona/stt): Transcribes spoken input in real-time using **Sparrow**, Tavus's smart turn taking model. It supports natural turn-taking with semantic and lexical analysis, allowing for dynamic interruptions and accurate transcription.

- [**LLM Layer**](/sections/conversational-video-interface/persona/llm): Generates responses based on the user's input and the persona’s configured context. Tavus provides ultra-low-latency, optimized LLMs by default, but you can integrate a custom model if needed.

- [**TTS Layer**](/sections/conversational-video-interface/persona/tts): Converts the generated text into audio. Tavus supports multiple voice providers including Cartesia, ElevenLabs, and PlayHT, giving you flexibility over voice style and latency.

- **Realtime Replica Layer**: Streams visually expressive avatar responses using **Phoenix**, Tavus's replica rendering model. It provides high-quality, low-latency output with synchronized lip-sync, facial gestures, and emotional cues to deliver lifelike interactions.
