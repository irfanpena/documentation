---
title: CVI Overview
sidebarTitle: Overview
description: Learn what CVI is and its features.
---

<Frame>
![](/images/devmode.png)
</Frame>

Conversational Video Interface (CVI) is a framework for creating real-time video interactions with AI. It enables AI agents to see, hear, and respond naturally, mirroring human conversation.

CVI consists of three core components:
- [**Persona**](/sections/conversational-video-interface/persona/overview): Defines the AI agent’s behavior, tone, knowledge, and capabilities. Shaping how it responds during a conversation.
- [**Replica**](/sections/replica/overview): Renders the AI agent’s visual appearance, with facial animations synced to speech for a lifelike presence using the Phoenix-3 model.
- [**Conversation**](/sections/conversational-video-interface/conversation/overview): A real-time video call session where users interact with the AI agent powered by the configured persona and replica.


## Key Features

<CardGroup cols={2}>
  
<Card title="Natural Interaction" icon="face-smile-beam">
CVI uses facial cues, body language, and real-time turn-taking to enable natural, human-like conversations.
</Card>

<Card title="Modular pipeline" icon="layer-group">
Customize the Perception, STT, LLM and TTS layers to control identity, behavior, and responses.
</Card>

<Card title="Lifelike AI replicas" icon="user-robot">
Choose from 100+ realistic avatars or create custom digital twins with human-like voice and expression.
</Card>

<Card title="Multilingual support" icon="globe">
Hold natural conversations in 30+ languages using the supported TTS engines.
</Card>

<Card title="World's lowest latency" icon="bolt">
Experience real-time interactions with ~600ms response time and smooth turn-taking.
</Card>
</CardGroup>


## Layers

The CVI is built on a modular layer system. Each layer can be customized through the [Persona configuration](/sections/conversational-video-interface/persona/overview) to match your specific requirements:

* **Transport (WebRTC)**
* **Perception**
* **STT (Speech-to-Text)**
* **LLM (Language Model)**
* **TTS (Text-to-Speech)**
* **Realtime Replica video output**

With these configurable layers, you can:

* Integrate your own LLM or use Tavus-optimized models with function calling.
* Customize STT and TTS engines for full control over voice and transcription.
* Configure smart turn detection and adjust sensitivity for interruptions and pauses.
* Access video streams directly to build a fully custom user interface.




## Getting Started
You can quickly create a conversation by using the [Tavus Platform](https://platform.tavus.io/) or following the steps in the [Quickstart](/sections/conversational-video-interface/full-mode) guide.
