---
title: Conversational Video Interface - Overview
sidebarTitle: Overview
description: Explore how CVI enables real-time, humanlike video interactions through configurable personas, lifelike replicas.
---

<Frame>
![](/images/devmode.png)
</Frame>
Conversational Video Interface (CVI) is a framework for creating real-time multimodal video interactions with AI. It enables AI agents to see, hear, and respond naturally, mirroring human conversation.

## Key Concepts
CVI is built around three core concepts that work together to create real-time, humanlike interactions with AI agents:
<CardGroup cols={3}>

  <Card title="Persona" icon="heart-pulse" href="/sections/conversational-video-interface/persona/overview">
    The **Persona** defines the agent’s behavior, tone, and knowledge. It also configures the CVI layer and pipeline.
  </Card>

  <Card title="Replica" icon="user-group" href="/sections/replica/overview">
    The **Replica** brings the persona to life visually. It renders a photorealistic human-like avatar using the **Phoenix-3** model.
  </Card>

  <Card title="Conversation" icon="video" href="/sections/conversational-video-interface/conversation/overview">
    A **Conversation** is a real-time video session that connects the persona and replica through a WebRTC connection.
  </Card>

</CardGroup>


## Key Features

<CardGroup cols={2}>
  
<Card title="Natural Interaction" icon="face-smile-beam">
CVI uses facial cues, body language, and real-time turn-taking to enable natural, human-like conversations.
</Card>

<Card title="Modular pipeline" icon="layer-group">
Customize the Perception, STT, LLM and TTS layers to control identity, behavior, and responses.
</Card>

<Card title="Lifelike AI replicas" icon="user-robot">
Choose from 100+ realistic avatars or create custom digital twins with human-like voice and expression.
</Card>

<Card title="Multilingual support" icon="globe">
Hold natural conversations in 30+ languages using the supported TTS engines.
</Card>

<Card title="World's lowest latency" icon="bolt">
Experience real-time interactions with ~600ms response time and smooth turn-taking.
</Card>
</CardGroup>


## Layers

The Conversational Video Interface (CVI) uses a modular layer system to process input and generate real-time, human-like responses. Each layer is configured through the <a href="/sections/conversational-video-interface/persona/overview" target="_blank">Persona</a>.

Here’s how the layers interact:

1. User speaks via a WebRTC stream.
2. Perception captures visual input (e.g., expressions, gaze) for added context to LLM.
3. STT transcribes user speech to text.
4. LLM processes the inputs and generates a text response.
5. TTS converts the response to speech.
6. Realtime Replica renders digital human with synchronized speech and expressions.
7. User sees the digital human respond in real time.



## Getting Started
You can quickly create a conversation by using the <a href="https://platform.tavus.io/" target="_blank">Tavus Platform</a> or following the steps in the <a href="/sections/conversational-video-interface/quickstart/use-the-full-pipeline" target="_blank">Quickstart</a> guide.
