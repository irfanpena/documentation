---
title: "Overview"
sidebarTitle: "Overview"
description: "CVI enables real-time, human-like video interactions through configurable lifelike replicas."
---

<Frame>
  ![](/images/devmode.png)
</Frame>

Conversational Video Interface (CVI) is a framework for creating real-time multimodal video interactions with AI. It enables an AI agent to see, hear, and respond naturally, mirroring human conversation.

CVI is the world’s fastest interface of its kind. It allows you to map a human face and conversational ability onto your AI agent. With CVI, you can achieve utterance-to-utterance latency with SLAs under 1 second. This is the full round-trip time for a participant to say something and the replica to reply.

CVI provides a comprehensive solution, with the option to plug in your existing components as required.

## Key Concepts

CVI is built around three core concepts that work together to create real-time, humanlike interactions with an AI agent:

<CardGroup cols={3}>
  <Card title="Persona" icon="heart-pulse" href="/sections/conversational-video-interface/persona/overview">
    The **Persona** defines the agent’s behavior, tone, and knowledge. It also configures the CVI layer and pipeline.
  </Card>
  <Card title="Replica" icon="user-group" href="/sections/replica/overview">
    The **Replica** brings the persona to life visually. It renders a photorealistic human-like avatar using the **Phoenix-3** model.
  </Card>
  <Card title="Conversation" icon="video" href="/sections/conversational-video-interface/conversation/overview">
    A **Conversation** is a real-time video session that connects the persona and replica through a WebRTC connection.
  </Card>
</CardGroup>

## Key Features

<CardGroup cols={2}>
  <Card title="Natural Interaction" icon="face-smile-beam">
    CVI uses facial cues, body language, and real-time turn-taking to enable natural, human-like conversations.
  </Card>
  <Card title="Modular pipeline" icon="layer-group">
    Customize the Perception, STT, LLM and TTS layers to control identity, behavior, and responses.
  </Card>
  <Card title="Lifelike AI replicas" icon="user-robot">
    Choose from 100\+ realistic avatars or create custom digital twins with human-like voice and expression.
  </Card>
  <Card title="Multilingual support" icon="globe">
    Hold natural conversations in 30\+ languages using the supported TTS engines.
  </Card>
  <Card title="World's lowest latency" icon="bolt">
    Experience real-time interactions with ~600ms response time and smooth turn-taking.
  </Card>
</CardGroup>

## Layers

The Conversational Video Interface (CVI) uses a modular layer system to process input and generate real-time, human-like responses. Each layer is configured through the <a href="/sections/conversational-video-interface/persona/overview" target="_blank">Persona</a>.

Here’s how the layers interact:
<AccordionGroup>

  <Accordion title="1. Transport" icon="right-left">
    Handles real-time audio and video streaming using WebRTC (powered by Daily). This layer captures the user's microphone and camera input and delivers output back to the user.  

    This layer is always enabled. You can configure input/output for audio (mic) and video (camera).
  </Accordion>

  <Accordion title="2. Perception" icon="eye">
    Uses <a href="/sections/conversational-video-interface/raven" target="_blank">Raven</a> to analyze user expressions, gaze, background, and screen content. This visual context helps the replica understand and respond more naturally.
  </Accordion>

  <Accordion title="3. Speech Recognition (STT)" icon="ear-listen">
    Powered by <a href="/sections/conversational-video-interface/persona/stt" target="_blank">Sparrow</a>, this layer transcribes user speech in real time with lexical and semantic awareness. It enables smart, natural turn-taking through fast, intelligent interruptions.
  </Accordion>

  <Accordion title="4. LLM" icon="brain">
    Processes the user's transcribed speech and visual input using a low-latency LLM. Tavus provides ultra-low latency optimized LLMs or lets you integrate your own.
  </Accordion>

  <Accordion title="5. Text-to-Speech (TTS)" icon="volume-high">
    Converts the LLM response into speech using the supported TTS Engines (Cartesia **(Default)**, ElevenLabs, PlayHT).
  </Accordion>

  <Accordion title="6. Realtime Replica" icon="face-smile">
    Delivers a high-quality, synchronized digital human response using Tavus's real-time avatar engine powered by **Phoenix**.
  </Accordion>

</AccordionGroup>


## Getting Started

You can quickly create a conversation by using the <a href="https://platform.tavus.io/" target="_blank">Tavus Platform</a> or following the steps in the <a href="/sections/conversational-video-interface/quickstart/use-the-full-pipeline" target="_blank">Quickstart</a> guide.
